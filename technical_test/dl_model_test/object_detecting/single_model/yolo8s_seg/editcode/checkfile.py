import os
from collections import defaultdict

# ê²½ë¡œ ì„¤ì •
dataset_path = r"C:\Users\Administrator\Downloads\merged_dataset\fine_tune_dataset"
splits = ["train", "valid", "test"]

class_counts = defaultdict(int)         # í´ë˜ìŠ¤ë³„ ì´ ê°ì²´ ìˆ˜
class_file_counts = defaultdict(set)    # í´ë˜ìŠ¤ë³„ ë“±ì¥í•œ íŒŒì¼ ì´ë¦„ ì§‘í•©

for split in splits:
    label_dir = os.path.join(dataset_path, split, "labels")
    if not os.path.exists(label_dir):
        print(f"âŒ {split}/labels ë””ë ‰í† ë¦¬ ì—†ìŒ")
        continue

    for label_file in os.listdir(label_dir):
        if not label_file.endswith(".txt"):
            continue

        label_path = os.path.join(label_dir, label_file)
        with open(label_path, 'r') as f:
            lines = f.readlines()
            seen_in_file = set()  # ì¤‘ë³µ í´ë˜ìŠ¤ ë°©ì§€

            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 1:
                    class_id = parts[0]
                    class_counts[class_id] += 1
                    seen_in_file.add(class_id)

            for class_id in seen_in_file:
                class_file_counts[class_id].add(label_file)

# ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Š fine_tune_dataset í´ë˜ìŠ¤ë³„ ìš”ì•½:")
for class_id in sorted(class_counts.keys(), key=int):
    total_obj = class_counts[class_id]
    file_count = len(class_file_counts[class_id])
    print(f" - í´ë˜ìŠ¤ {class_id}: {total_obj}ê°œ ê°ì²´ / {file_count}ê°œ íŒŒì¼ì— ë“±ì¥")
